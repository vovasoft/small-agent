from typing import List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import json  # ç¡®ä¿å¯¼å…¥json
import uuid

from llmops.agents.state import AgentState, ReportOutline, ReportSection, MetricRequirement, convert_numpy_types
from llmops.agents.datadev.llm import get_llm


class OutlineGenerator:
    """å¤§çº²ç”Ÿæˆæ™ºèƒ½ä½“ï¼šå°†æŠ¥å‘Šéœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–å¤§çº²"""

    def __init__(self, llm):
        self.llm = llm.with_structured_output(ReportOutline)

    def create_prompt(self, question: str, sample_data: List[Dict]) -> str:
        """åˆ›å»ºå¤§çº²ç”Ÿæˆæç¤º"""

        available_fields = list(sample_data[0].keys()) if sample_data else []
        sample_str = json.dumps(sample_data[:2], ensure_ascii=False, indent=2)

        # å…³é”®ä¿®å¤ï¼šæä¾›è¯¦ç»†çš„å­—æ®µè¯´æ˜å’Œç¤ºä¾‹
        return f"""ä½ æ˜¯é“¶è¡Œæµæ°´æŠ¥å‘Šå¤§çº²ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œæ ·æœ¬æ•°æ®ï¼Œç”Ÿæˆä¸“ä¸šã€å¯æ‰§è¡Œçš„æŠ¥å‘Šå¤§çº²ã€‚

éœ€æ±‚åˆ†æï¼š
{question}

å¯ç”¨å­—æ®µï¼š
{', '.join(available_fields)}

æ ·æœ¬æ•°æ®ï¼š
{sample_str}

è¾“å‡ºè¦æ±‚ï¼ˆå¿…é¡»ç”Ÿæˆæœ‰æ•ˆçš„JSONï¼‰ï¼š
1. report_title: æŠ¥å‘Šæ ‡é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰
2. sections: ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚å¿…é¡»åŒ…å«ï¼š
   - section_id: ç« èŠ‚å”¯ä¸€IDï¼ˆå¦‚"sec_1", "sec_2"ï¼‰
   - title: ç« èŠ‚æ ‡é¢˜
   - description: ç« èŠ‚æè¿°
   - metrics_needed: æ‰€éœ€æŒ‡æ ‡IDåˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼Œå¯ä¸ºç©ºï¼‰
3. global_metrics: å…¨å±€æŒ‡æ ‡åˆ—è¡¨ï¼Œæ¯ä¸ªæŒ‡æ ‡å¿…é¡»åŒ…å«ï¼š
   - metric_id: æŒ‡æ ‡å”¯ä¸€IDï¼ˆå¦‚"total_income", "avg_balance"ï¼‰
   - metric_name: æŒ‡æ ‡åç§°
   - calculation_logic: è®¡ç®—é€»è¾‘æè¿°
   - required_fields: æ‰€éœ€å­—æ®µåˆ—è¡¨
   - dependencies: ä¾èµ–çš„å…¶ä»–æŒ‡æ ‡IDï¼ˆå¯ä¸ºç©ºï¼‰

é‡è¦æç¤ºï¼š
- å¿…é¡»ç”Ÿæˆsection_idï¼Œæ ¼å¼ä¸º"sec_1", "sec_2"ç­‰
- å¿…é¡»ç”Ÿæˆmetric_idï¼Œæ ¼å¼ä¸ºå­—æ¯+ä¸‹åˆ’çº¿+æè¿°
- metrics_neededå¿…é¡»æ˜¯å­—ç¬¦ä¸²æ•°ç»„
- ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨ï¼Œä¸èƒ½ç¼ºå¤±

è¾“å‡ºç¤ºä¾‹ï¼š
{{
  "report_title": "2024å¹´ç¬¬ä¸‰å­£åº¦åˆ†ææŠ¥å‘Š",
  "sections": [
    {{
      "section_id": "sec_1",
      "title": "æ”¶å…¥æ¦‚è§ˆ",
      "description": "åˆ†ææ”¶å…¥æ€»é¢",
      "metrics_needed": ["total_income", "avg_income"]
    }}
  ],
  "global_metrics": [
    {{
      "metric_id": "total_income",
      "metric_name": "æ€»æ”¶å…¥",
      "calculation_logic": "sum of all income transactions",
      "required_fields": ["txAmount", "txDirection"],
      "dependencies": []
    }}
  ]
}}"""

    async def generate(self, state: AgentState) -> ReportOutline:
        """å¼‚æ­¥ç”Ÿæˆå¤§çº²ï¼ˆä¿®å¤ç‰ˆï¼šè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±å­—æ®µï¼‰"""
        prompt = self.create_prompt(
            question=state["question"],
            sample_data=state["data_set"][:2]
        )

        messages = [
            ("system", "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æŠ¥å‘Šå¤§çº²ç”Ÿæˆä¸“å®¶ï¼Œå¿…é¡»è¾“å‡ºå®Œæ•´ã€æœ‰æ•ˆçš„JSONæ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µã€‚"),
            ("user", prompt)
        ]

        outline = await self.llm.ainvoke(messages)

        # å…³é”®ä¿®å¤ï¼šåå¤„ç†ï¼Œè¡¥å…¨ç¼ºå¤±çš„section_idå’Œmetric_id
        outline = self._post_process_outline(outline)

        return outline

    def _post_process_outline(self, outline: ReportOutline) -> ReportOutline:
        """
        åå¤„ç†å¤§çº²ï¼Œè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„å¿…éœ€å­—æ®µ
        """
        # ä¸ºç« èŠ‚è¡¥å…¨section_id
        for idx, section in enumerate(outline.sections):
            if not section.section_id:
                section.section_id = f"sec_{idx + 1}"

            # ç¡®ä¿metrics_neededæ˜¯åˆ—è¡¨
            if not isinstance(section.metrics_needed, list):
                section.metrics_needed = []

        # ä¸ºæŒ‡æ ‡è¡¥å…¨metric_idå’Œdependencies
        for idx, metric in enumerate(outline.global_metrics):
            if not metric.metric_id:
                metric.metric_id = f"metric_{idx + 1}"

            # ç¡®ä¿dependenciesæ˜¯åˆ—è¡¨
            if not isinstance(metric.dependencies, list):
                metric.dependencies = []

            # æ¨æ–­required_fieldsï¼ˆå¦‚æœä¸ºç©ºï¼‰
            if not metric.required_fields:
                metric.required_fields = self._infer_required_fields(
                    metric.calculation_logic
                )

        return outline

    def _infer_required_fields(self, logic: str) -> List[str]:
        """ä»è®¡ç®—é€»è¾‘æ¨æ–­æ‰€éœ€å­—æ®µ"""
        field_mapping = {
            "æ”¶å…¥": ["txAmount", "txDirection"],
            "æ”¯å‡º": ["txAmount", "txDirection"],
            "ä½™é¢": ["txBalance"],
            "å¯¹æ‰‹æ–¹": ["txCounterparty"],
            "æ—¥æœŸ": ["txDate"],
            "æ—¶é—´": ["txTime", "txDate"],
            "æ‘˜è¦": ["txSummary"],
            "åˆ›å»ºæ—¶é—´": ["createdAt"]
        }

        fields = []
        for keyword, field_list in field_mapping.items():
            if keyword in logic:
                fields.extend(field_list)

        return list(set(fields))


async def outline_node(state: AgentState) -> AgentState:
    """å¤§çº²ç”ŸæˆèŠ‚ç‚¹ï¼šè®¾ç½®æˆåŠŸæ ‡å¿—ï¼Œé˜²æ­¢é‡å¤ç”Ÿæˆ"""

    llm = get_llm()
    generator = OutlineGenerator(llm)

    try:
        # å¼‚æ­¥ç”Ÿæˆå¤§çº²
        outline = await generator.generate(state)

        # æ›´æ–°çŠ¶æ€
        new_state = state.copy()
        new_state["outline_draft"] = outline
        new_state["outline_version"] += 1

        # é˜²æŠ¤ï¼šè®¾ç½®æˆåŠŸæ ‡å¿—
        new_state["outline_ready"] = True  # æ˜ç¡®æ ‡å¿—ï¼šå¤§çº²å·²å°±ç»ª

        new_state["metrics_requirements"] = outline.global_metrics
        new_state["metrics_pending"] = outline.global_metrics.copy()  # å¾…è®¡ç®—æŒ‡æ ‡
        new_state["messages"].append(
            ("ai", f"âœ… å¤§çº²ç”Ÿæˆå®Œæˆ v{new_state['outline_version']}ï¼š{outline.report_title}")
        )

        print(f"\nğŸ“ å¤§çº²å·²ç”Ÿæˆï¼š{outline.report_title}")
        print(f"   ç« èŠ‚æ•°ï¼š{len(outline.sections)}")
        print(f"   æŒ‡æ ‡æ•°ï¼š{len(outline.global_metrics)}")

        # æ–°å¢ï¼šè¯¦ç»†æ‰“å°å¤§çº²å†…å®¹
        print("\n" + "=" * 70)
        print("ğŸ“‹ è¯¦ç»†å¤§çº²å†…å®¹")
        print("=" * 70)
        print(json.dumps(outline.dict(), ensure_ascii=False, indent=2))
        print("=" * 70)

        # å…³é”®ä¿®å¤ï¼šè¿”å›å‰æ¸…ç†çŠ¶æ€
        return convert_numpy_types(new_state)

    except Exception as e:
        print(f"âš ï¸ å¤§çº²ç”Ÿæˆå‡ºé”™: {e}ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")

        # åˆ›å»ºé»˜è®¤å¤§çº²
        default_outline = ReportOutline(
            report_title="é»˜è®¤äº¤æ˜“åˆ†ææŠ¥å‘Š",
            sections=[
                ReportSection(
                    section_id="sec_1",
                    title="äº¤æ˜“æ¦‚è§ˆ",
                    description="åŸºç¡€äº¤æ˜“æƒ…å†µåˆ†æ",
                    metrics_needed=["total_transactions", "total_income", "total_expense"]
                )
            ],
            global_metrics=[
                MetricRequirement(
                    metric_id="total_transactions",
                    metric_name="æ€»äº¤æ˜“ç¬”æ•°",
                    calculation_logic="count all transactions",
                    required_fields=["txId"],
                    dependencies=[]
                ),
                MetricRequirement(
                    metric_id="total_income",
                    metric_name="æ€»æ”¶å…¥",
                    calculation_logic="sum of income transactions",
                    required_fields=["txAmount", "txDirection"],
                    dependencies=[]
                )
            ]
        )

        new_state = state.copy()
        new_state["outline_draft"] = default_outline
        new_state["outline_version"] += 1
        new_state["outline_ready"] = True  # å³ä½¿é»˜è®¤ä¹Ÿæ ‡è®°ä¸ºå°±ç»ª
        new_state["metrics_requirements"] = default_outline.global_metrics
        new_state["messages"].append(
            ("ai", f"âš ï¸ ä½¿ç”¨é»˜è®¤å¤§çº² v{new_state['outline_version']}")
        )

        # æ–°å¢ï¼šè¯¦ç»†æ‰“å°é»˜è®¤å¤§çº²å†…å®¹
        print("\n" + "=" * 70)
        print("ğŸ“‹ é»˜è®¤å¤§çº²å†…å®¹")
        print("=" * 70)
        print(json.dumps(default_outline.dict(), ensure_ascii=False, indent=2))
        print("=" * 70)

        # å…³é”®ä¿®å¤ï¼šè¿”å›å‰æ¸…ç†çŠ¶æ€
        return convert_numpy_types(new_state)