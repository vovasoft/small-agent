"""
æŠ¥å‘Šå¤§çº²ç”ŸæˆAgent (Report Outline Generation Agent)
===============================================

æ­¤Agentè´Ÿè´£æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œæ•°æ®æ ·æœ¬ï¼Œç”Ÿæˆä¸“ä¸šçš„æŠ¥å‘Šå¤§çº²ç»“æ„ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åˆ†æç”¨æˆ·éœ€æ±‚ï¼šç†è§£æŠ¥å‘Šç›®æ ‡å’Œå…³é”®æŒ‡æ ‡
2. æ•°æ®ç»“æ„åˆ†æï¼šè¯†åˆ«å¯ç”¨å­—æ®µå’Œæ•°æ®ç‰¹å¾
3. å¤§çº²ç”Ÿæˆï¼šåˆ›å»ºç»“æ„åŒ–çš„æŠ¥å‘Šç« èŠ‚å’ŒæŒ‡æ ‡éœ€æ±‚
4. æ™ºèƒ½æ¨æ–­ï¼šè‡ªåŠ¨æ¨æ–­æ‰€éœ€å­—æ®µå’Œè®¡ç®—é€»è¾‘

å·¥ä½œæµç¨‹ï¼š
1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢å’Œæ•°æ®æ ·æœ¬
2. åˆ†ææ•°æ®ç»“æ„å’Œå¯ç”¨å­—æ®µ
3. ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜å’Œç« èŠ‚ç»“æ„
4. å®šä¹‰å…¨å±€æŒ‡æ ‡éœ€æ±‚
5. è¿”å›ç»“æ„åŒ–çš„å¤§çº²å¯¹è±¡

æŠ€æœ¯å®ç°ï¼š
- ä½¿ç”¨LangChainå’Œç»“æ„åŒ–è¾“å‡º
- æ”¯æŒå¼‚æ­¥å¤„ç†
- è‡ªåŠ¨å­—æ®µæ¨æ–­å’Œè¡¥å…¨
- é”™è¯¯å¤„ç†å’Œé»˜è®¤å€¼æä¾›

ä½œè€…: Big Agent Team
ç‰ˆæœ¬: 1.0.0
åˆ›å»ºæ—¶é—´: 2024-12-20
"""

from typing import List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
import json
import os
import uuid
import requests
from datetime import datetime

from pydantic import BaseModel, Field


# æ•°æ®æ¨¡å‹å®šä¹‰ï¼ˆä¸ç°æœ‰é¡¹ç›®å…¼å®¹ï¼‰
class MetricRequirement(BaseModel):
    """æŒ‡æ ‡éœ€æ±‚å®šä¹‰"""
    metric_id: str = Field(description="æŒ‡æ ‡å”¯ä¸€æ ‡è¯†ï¼Œå¦‚ 'total_income_jan'")
    metric_name: str = Field(description="æŒ‡æ ‡ä¸­æ–‡åç§°")
    calculation_logic: str = Field(description="è®¡ç®—é€»è¾‘æè¿°")
    required_fields: List[str] = Field(description="æ‰€éœ€å­—æ®µ")
    dependencies: List[str] = Field(default_factory=list, description="ä¾èµ–çš„å…¶ä»–æŒ‡æ ‡ID")


class ReportSection(BaseModel):
    """æŠ¥å‘Šå¤§çº²ç« èŠ‚"""
    section_id: str = Field(description="ç« èŠ‚ID")
    title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    description: str = Field(description="ç« èŠ‚å†…å®¹è¦æ±‚")
    metrics_needed: List[str] = Field(description="æ‰€éœ€æŒ‡æ ‡IDåˆ—è¡¨")


class ReportOutline(BaseModel):
    """å®Œæ•´æŠ¥å‘Šå¤§çº²"""
    report_title: str = Field(description="æŠ¥å‘Šæ ‡é¢˜")
    sections: List[ReportSection] = Field(description="ç« èŠ‚åˆ—è¡¨")
    global_metrics: List[MetricRequirement] = Field(description="å…¨å±€æŒ‡æ ‡åˆ—è¡¨")


class OutlineGeneratorAgent:
    """å¤§çº²ç”Ÿæˆæ™ºèƒ½ä½“ï¼šå°†æŠ¥å‘Šéœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–å¤§çº²"""

    def __init__(self, api_key: str, base_url: str = "https://api.deepseek.com"):
        """
        åˆå§‹åŒ–å¤§çº²ç”ŸæˆAgent

        Args:
            api_key: DeepSeek APIå¯†é’¥
            base_url: DeepSeek APIåŸºç¡€URL
        """
        self.llm = ChatOpenAI(
            model="deepseek-chat",
            api_key=api_key,
            base_url=base_url,
            temperature=0.1
        )

        # åˆå§‹åŒ–APIè°ƒç”¨è·Ÿè¸ª
        self.api_calls = []

        # è·å–å¯ç”¨çš„çŸ¥è¯†å…ƒæ•°æ®
        self.available_knowledge = self._load_available_knowledge()



    def _convert_new_format_to_outline(self, new_format_data: Dict[str, Any]) -> Dict[str, Any]:
        """å°†æ–°çš„JSONæ ¼å¼è½¬æ¢ä¸ºåŸæ¥çš„ReportOutlineæ ¼å¼"""

        # è½¬æ¢sections
        sections = []
        for section_data in new_format_data.get("sections", []):
            # ä»metricsä¸­æå–æŒ‡æ ‡åç§°
            metrics_needed = []
            for metric_type in ["calculation_metrics", "statistical_metrics", "analysis_metrics"]:
                for metric in section_data.get("metrics", {}).get(metric_type, []):
                    # è¿™é‡Œå¯ä»¥æ ¹æ®metric_nameæ˜ å°„åˆ°å®é™…çš„metric_id
                    # æš‚æ—¶ä½¿ç”¨metric_nameä½œä¸ºmetric_id
                    metrics_needed.append(metric.get("metric_name", ""))

            section = {
                "section_id": section_data.get("section_id", ""),
                "title": section_data.get("section_title", ""),
                "description": section_data.get("section_description", ""),
                "metrics_needed": metrics_needed
            }
            sections.append(section)

        # ç”Ÿæˆglobal_metricsï¼šä½¿ç”¨çŸ¥è¯†IDè¿›è¡ŒåŒ¹é…ï¼Œå¹¶å¼ºåˆ¶æ·»åŠ æ›´å¤šå†œä¸šç›¸å…³æŒ‡æ ‡
        global_metrics = []
        used_knowledge_ids = set()

        # é¦–å…ˆå¤„ç†LLMç”Ÿæˆçš„æŒ‡æ ‡
        for section in sections:
            for metric_name in section["metrics_needed"]:
                # æŸ¥æ‰¾å¯¹åº”çš„æŒ‡æ ‡æè¿°ï¼ˆä»åŸå§‹æ•°æ®ä¸­è·å–ï¼‰
                metric_description = ""
                for section_data in new_format_data.get("sections", []):
                    for metric_type in ["calculation_metrics", "statistical_metrics", "analysis_metrics"]:
                        for metric in section_data.get("metrics", {}).get(metric_type, []):
                            if metric.get("metric_name") == metric_name:
                                metric_description = metric.get("metric_description", "")
                                break
                        if metric_description:
                            break
                    if metric_description:
                        break

                # ä½¿ç”¨çŸ¥è¯†IDåŒ¹é…ç®—æ³•æ‰¾åˆ°æœ€ä½³åŒ¹é…
                knowledge_id = self._match_metric_to_knowledge(metric_name, metric_description)

                # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„çŸ¥è¯†IDï¼Œä½¿ç”¨å®ƒä½œä¸ºmetric_id
                if knowledge_id and knowledge_id not in used_knowledge_ids:
                    global_metrics.append({
                        "metric_id": knowledge_id,  # ä½¿ç”¨çŸ¥è¯†IDä½œä¸ºmetric_id
                        "metric_name": metric_name,
                        "calculation_logic": f"ä½¿ç”¨è§„åˆ™å¼•æ“è®¡ç®—{metric_name}: {metric_description}",
                        "required_fields": ["transactions"],  # è§„åˆ™å¼•æ“ä½¿ç”¨transactionsæ•°æ®
                        "dependencies": []
                    })
                    used_knowledge_ids.add(knowledge_id)
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„çŸ¥è¯†IDï¼Œç”Ÿæˆä¸€ä¸ªåŸºæœ¬çš„MetricRequirementä½œä¸ºå¤‡é€‰
                    if not any(m.get("metric_id") == metric_name for m in global_metrics):
                        print(f"âš ï¸ æŒ‡æ ‡ '{metric_name}' æœªæ‰¾åˆ°åŒ¹é…çš„çŸ¥è¯†IDï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                        global_metrics.append({
                            "metric_id": metric_name,
                            "metric_name": metric_name,
                            "calculation_logic": f"è®¡ç®—{metric_name}: {metric_description}",
                            "required_fields": ["txAmount", "txDirection"],
                            "dependencies": []
                        })

        # æ³¨æ„ï¼šç°åœ¨ä¾èµ–LLMæ ¹æ®æç¤ºè¯ç”ŸæˆåŒ…å«æ‰€æœ‰å¿…éœ€æŒ‡æ ‡çš„å¤§çº²ï¼Œä¸å†åœ¨ä»£ç ä¸­å¼ºåˆ¶æ·»åŠ 

        # å¦‚æœLLMæ²¡æœ‰æä¾›ä»»ä½•æŒ‡æ ‡ï¼Œåˆ™è‡ªåŠ¨è¡¥å……åŸºç¡€æŒ‡æ ‡
        if not global_metrics:
            print("âš ï¸ LLMæœªæä¾›æŒ‡æ ‡ï¼Œä½¿ç”¨é»˜è®¤åŸºç¡€æŒ‡æ ‡")
            available_metrics = self._load_available_metrics()

            # é€‰æ‹©å‰5ä¸ªåŸºç¡€æŒ‡æ ‡
            base_metrics = [m for m in available_metrics if m.get('type') == 'åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡'][:5]

            for metric in base_metrics:
                metric_name = metric['name']
                knowledge_id = f"metric-{metric_name}"
                if sections:  # ç¡®ä¿æœ‰ç« èŠ‚
                    sections[0]["metrics_needed"].append(knowledge_id)  # æ·»åŠ åˆ°ç¬¬ä¸€ä¸ªç« èŠ‚
                global_metrics.append({
                    "metric_id": knowledge_id,
                    "metric_name": metric_name,
                    "calculation_logic": f"ä½¿ç”¨è§„åˆ™å¼•æ“è®¡ç®—{metric_name}: {metric.get('description', '')}",
                    "required_fields": ["transactions"],
                    "dependencies": []
                })

        print(f"ğŸ“Š æœ€ç»ˆç”Ÿæˆ {len(global_metrics)} ä¸ªæŒ‡æ ‡")

        return {
            "report_title": new_format_data.get("chapter_title", "æµæ°´åˆ†ææŠ¥å‘Š"),
            "sections": sections,
            "global_metrics": global_metrics
        }

    def create_prompt(self) -> str:
        """åˆ›å»ºå¤§çº²ç”Ÿæˆæç¤º"""

        # ä»APIåŠ¨æ€è·å–å¯ç”¨çš„æŒ‡æ ‡åˆ—è¡¨
        available_metrics = self._load_available_metrics()

        # æ„å»ºæŒ‡æ ‡åˆ—è¡¨æ–‡æœ¬
        metrics_list_text = "æŒ‡æ ‡åç§°\tæŒ‡æ ‡ç±»å‹\tæŒ‡æ ‡æè¿°\n"
        for metric in available_metrics:
            metrics_list_text += f"{metric['name']}\t{metric.get('type', 'è®¡ç®—å‹æŒ‡æ ‡')}\t{metric.get('description', '')}\n"

        # æ„å»ºåŸºç¡€æç¤ºè¯
        base_prompt = f"""[è§’è‰²å®šä¹‰]
ä½ çš„è§’è‰²æ˜¯: æµæ°´åˆ†ææŠ¥å‘Šçš„å¤§çº²ç”Ÿæˆæ¨¡å—ã€‚
ä½ çš„ç›®æ ‡æ˜¯:
åŸºäºè¾“å…¥çš„æµæ°´åˆ†æä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯,
ç”Ÿæˆä¸€ä»½å¯äº¤ä»˜ã€ç»“æ„æ¸…æ™°ã€å¯è¢«ç¨‹åºè§£æçš„æµæ°´åˆ†ææŠ¥å‘Šå¤§çº²,
å¹¶ä»¥ç»“æ„åŒ– JSON çš„å½¢å¼ï¼Œæ˜ç¡®æ¯ä¸ªç« èŠ‚åŠå…¶ä¸‹å±åˆ†æä¸»é¢˜æ‰€éœ€çš„åˆ†ææŒ‡æ ‡ä¸åˆ†æé¡¹è¦æ±‚,
ä»¥æŒ‡å¯¼åç»­åˆ†æèƒ½åŠ›çš„è°ƒç”¨ã€‚

[èŒè´£è¾¹ç•Œ]
ä½ åªèƒ½å®Œæˆä»¥ä¸‹äº‹é¡¹:
1.ç¡®å®šæµæ°´åˆ†ææŠ¥å‘Šåº”åŒ…å«çš„ç« èŠ‚ç»“æ„
2.æ˜ç¡®æ¯ä¸ªç« èŠ‚ä¸‹éœ€è¦è¦†ç›–çš„åˆ†æä¸»é¢˜
3.ä¸ºæ¯ä¸ªåˆ†æä¸»é¢˜åˆ—å‡ºæ‰€éœ€çš„è®¡ç®—æŒ‡æ ‡ã€ç»Ÿè®¡æŒ‡æ ‡æˆ–åˆ†ææŒ‡æ ‡

ä½ ä¸å¾—åšä»¥ä¸‹ä»»ä½•äº‹æƒ…:
1.ä¸å¾—è®¡ç®—ä»»ä½•æŒ‡æ ‡
2.ä¸å¾—å¯¹æµæ°´æ•°æ®è¿›è¡Œåˆ†æ
3.ä¸å¾—åˆ¤æ–­äº¤æ˜“æ˜¯å¦å¼‚å¸¸æˆ–å­˜åœ¨é£é™©
4.ä¸å¾—ç”Ÿæˆä»»ä½•åˆ†æç»“è®ºã€åˆ¤æ–­æ€§æè¿°æˆ–æŠ¥å‘Šæ­£æ–‡
5.ä¸å¾—å†³å®šåˆ†ææ‰§è¡Œé¡ºåºæˆ–åˆ†ææ–¹æ³•

ä½ è¾“å‡ºçš„å†…å®¹ä»…æ˜¯"åˆ†æéœ€æ±‚æ¸…å•"ï¼Œè€Œä¸æ˜¯"åˆ†æç»“æœ"ã€‚

[å¯ç”¨æŒ‡æ ‡æ€»è§ˆ]
ç³»ç»Ÿå½“å‰æ”¯æŒ {len(available_metrics)} ä¸ªæŒ‡æ ‡ã€‚

[é‡è¦è¦æ±‚]
è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œå¯ç”¨æŒ‡æ ‡åˆ—è¡¨ï¼Œä»ä¸Šè¿°æŒ‡æ ‡ä¸­é€‰æ‹©æœ€ç›¸å…³çš„æŒ‡æ ‡ã€‚ä¼˜å…ˆé€‰æ‹©åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡å’Œæ—¶é—´åˆ†ææŒ‡æ ‡ï¼Œç¡®ä¿æŠ¥å‘Šçš„å®Œæ•´æ€§å’Œå®ç”¨æ€§ã€‚

[å¼ºåˆ¶è¦æ±‚]
ç”Ÿæˆå¤§çº²æ—¶ï¼Œè¯·ï¼š
1. ä»å¯ç”¨æŒ‡æ ‡ä¸­é€‰æ‹©åˆé€‚çš„æŒ‡æ ‡ç»„åˆ
2. ç¡®ä¿é€‰æ‹©çš„æŒ‡æ ‡èƒ½å¤Ÿæ»¡è¶³ç”¨æˆ·åˆ†æéœ€æ±‚
3. åœ¨metrics_neededæ•°ç»„ä¸­åˆ—å‡ºé€‰å®šçš„æŒ‡æ ‡åç§°
4. åœ¨global_metricsæ•°ç»„ä¸­åŒ…å«å¯¹åº”æŒ‡æ ‡çš„è¯¦ç»†å®šä¹‰

[å¯é€‰æ‹©çš„æŒ‡æ ‡åˆ—è¡¨]
{metrics_list_text}

[é‡è¦å…¼å®¹æ€§è¦æ±‚]
è™½ç„¶ä½ å¿…é¡»ä½¿ç”¨ä¸Šè¿°JSONç»“æ„è¾“å‡ºï¼Œä½†ä¸ºäº†ç¡®ä¿ä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§ï¼Œè¯·åœ¨è¾“å‡ºä¸­é¢å¤–åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- åœ¨æ ¹çº§åˆ«æ·»åŠ  "report_title": "æµæ°´åˆ†ææŠ¥å‘Š"
- åœ¨æ ¹çº§åˆ«æ·»åŠ  "global_metrics": [] (ç©ºæ•°ç»„æˆ–æ ¹æ®å®é™…éœ€æ±‚å¡«å……æŒ‡æ ‡å®šä¹‰)
- ç¡®ä¿è¾“å‡ºèƒ½è¢«ç°æœ‰ç³»ç»Ÿæ­£ç¡®è§£æå’Œä½¿ç”¨

[è¾“å‡ºæ ¼å¼è¦æ±‚]
ä½ å¿…é¡»ä¸”åªèƒ½ä»¥ JSON å­—ç¬¦ä¸² å½¢å¼è¾“å‡ºåˆ†æå¤§çº²ï¼Œä¸å¾—è¾“å‡ºä»»ä½•è§£é‡Šæ€§è‡ªç„¶è¯­è¨€ã€‚
JSON å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹ç»“æ„çº¦å®š:
{{
  "chapter_id": "string",
  "chapter_title": "string",
  "chapter_type": "string",
  "sections": [
    {{
      "section_id": "string",
      "section_title": "string",
      "section_description": "string",
      "metrics_needed": ["string"]
    }}
  ],
  "global_metrics": []
}}"""

        return base_prompt

        print(f"ğŸ“Š æœ€ç»ˆç”Ÿæˆ {len(global_metrics)} ä¸ªæŒ‡æ ‡")

        return {
            "report_title": new_format_data.get("chapter_title", "æµæ°´åˆ†ææŠ¥å‘Š"),
            "sections": sections,
            "global_metrics": global_metrics
        }


    async def generate_outline(self, question: str, industry: str, sample_data: List[Dict[str, Any]]) -> ReportOutline:
        """å¼‚æ­¥ç”Ÿæˆå¤§çº²ï¼ˆä¿®å¤ç‰ˆï¼šè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±å­—æ®µï¼‰"""
        prompt = self.create_prompt()

        # åœ¨promptæœ«å°¾æ·»åŠ ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯
        full_prompt = f"""{prompt}

ã€ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯ã€‘
è¡Œä¸šï¼š{industry}
äº§å“ç±»å‹ï¼šç»è¥è´·
å®¢ç¾¤ç±»å‹ï¼šå°å¾®ä¼ä¸š"""

        messages = [
            ("system", "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æŠ¥å‘Šå¤§çº²ç”Ÿæˆä¸“å®¶ï¼Œå¿…é¡»è¾“å‡ºå®Œæ•´ã€æœ‰æ•ˆçš„JSONæ ¼å¼ï¼ŒåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µã€‚"),
            ("user", full_prompt)
        ]

        # è®°å½•å¤§æ¨¡å‹è¾“å…¥
        print("========================================")
        print("[AGENT] OutlineGeneratorAgent (å¤§çº²ç”ŸæˆAgent)")
        print(f"[KNOWLEDGE_BASE] å·²åŠ è½½ {len(self.available_knowledge)} ä¸ªçŸ¥è¯†å…ƒæ•°æ®")
        if self.available_knowledge:
            sample_knowledge = self.available_knowledge[:3]  # æ˜¾ç¤ºå‰3ä¸ªä½œä¸ºç¤ºä¾‹
            print(f"[KNOWLEDGE_SAMPLE] ç¤ºä¾‹çŸ¥è¯†: {[k.get('id', '') for k in sample_knowledge]}")
        print("[MODEL_INPUT] OutlineGeneratorAgent:")
        print(f"[CONTEXT] åŸºäºç”¨æˆ·éœ€æ±‚å’Œæ•°æ®æ ·æœ¬ç”ŸæˆæŠ¥å‘Šå¤§çº²")
        print(f"Question: {question}")
        print(f"Sample data count: {len(sample_data)}")
        print("========================================")

        # æ‰§è¡ŒAPIè°ƒç”¨
        start_time = datetime.now()
        response = await self.llm.ainvoke(messages)
        end_time = datetime.now()

        # è§£æJSONå“åº”
        try:
            # ä»å“åº”ä¸­æå–JSONå†…å®¹
            content = response.content if hasattr(response, 'content') else str(response)
            # å°è¯•æ‰¾åˆ°JSONéƒ¨åˆ†
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                json_str = content[json_start:json_end]
                outline_data = json.loads(json_str)

                # è½¬æ¢æ–°çš„JSONæ ¼å¼ä¸ºåŸæ¥çš„ReportOutlineæ ¼å¼
                converted_data = self._convert_new_format_to_outline(outline_data)
                outline = ReportOutline(**converted_data)
            else:
                raise ValueError("No JSON found in response")
        except Exception as e:
            print(f"è§£æå¤§çº²å“åº”å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å¤§çº²")
            # ä¸åœ¨è¿™é‡Œåˆ›å»ºå¤§çº²ï¼Œåœ¨å‡½æ•°æœ«å°¾ç»Ÿä¸€å¤„ç†

        # è®°å½•APIè°ƒç”¨ç»“æœ
        call_id = f"api_mll_å¤§çº²ç”Ÿæˆ_{'{:.2f}'.format((end_time - start_time).total_seconds())}"
        api_call_info = {
            "call_id": call_id,
            "timestamp": end_time.isoformat(),
            "agent": "OutlineGeneratorAgent",
            "model": "deepseek-chat",
            "request": {
                "question": question,
                "sample_data_count": len(sample_data),
                "prompt": prompt,
                "start_time": start_time.isoformat()
            },
            "response": {
                "content": content,
                "end_time": end_time.isoformat(),
                "duration": (end_time - start_time).total_seconds()
            },
            "success": True
        }
        self.api_calls.append(api_call_info)

        # ä¿å­˜APIç»“æœåˆ°æ–‡ä»¶
        api_results_dir = "api_results"
        os.makedirs(api_results_dir, exist_ok=True)
        filename = f"{call_id}.json"
        filepath = os.path.join(api_results_dir, filename)

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(api_call_info, f, ensure_ascii=False, indent=2)
            print(f"[API_RESULT] ä¿å­˜APIç»“æœæ–‡ä»¶: {filepath}")
        except Exception as e:
            print(f"[ERROR] ä¿å­˜APIç»“æœæ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {str(e)}")

        # è®°å½•å¤§æ¨¡å‹è¾“å‡º
        print(f"[MODEL_OUTPUT] OutlineGeneratorAgent: {json.dumps(outline.dict() if hasattr(outline, 'dict') else outline, ensure_ascii=False)}")
        print("========================================")

        # åå¤„ç†ï¼Œè¡¥å…¨ç¼ºå¤±çš„section_idå’Œmetric_id
        outline = self._post_process_outline(outline)

        return outline

    def _post_process_outline(self, outline: ReportOutline) -> ReportOutline:
        """
        åå¤„ç†å¤§çº²ï¼Œè‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„å¿…éœ€å­—æ®µ
        """
        # ä¸ºç« èŠ‚è¡¥å…¨section_id
        for idx, section in enumerate(outline.sections):
            if not section.section_id:
                section.section_id = f"sec_{idx + 1}"

            # ç¡®ä¿metrics_neededæ˜¯åˆ—è¡¨
            if not isinstance(section.metrics_needed, list):
                section.metrics_needed = []

        # ä¸ºæŒ‡æ ‡è¡¥å…¨metric_idå’Œdependencies
        for idx, metric in enumerate(outline.global_metrics):
            if not metric.metric_id:
                metric.metric_id = f"metric_{idx + 1}"

            # ç¡®ä¿dependenciesæ˜¯åˆ—è¡¨
            if not isinstance(metric.dependencies, list):
                metric.dependencies = []

            # æ¨æ–­required_fieldsï¼ˆå¦‚æœä¸ºç©ºï¼‰
            if not metric.required_fields:
                metric.required_fields = self._infer_required_fields(
                    metric.calculation_logic
                )

        return outline

    def _infer_required_fields(self, logic: str) -> List[str]:
        """ä»è®¡ç®—é€»è¾‘æ¨æ–­æ‰€éœ€å­—æ®µ"""
        field_mapping = {
            "æ”¶å…¥": ["txAmount", "txDirection"],
            "æ”¯å‡º": ["txAmount", "txDirection"],
            "ä½™é¢": ["txBalance"],
            "å¯¹æ‰‹æ–¹": ["txCounterparty"],
            "æ—¥æœŸ": ["txDate"],
            "æ—¶é—´": ["txTime", "txDate"],
            "æ‘˜è¦": ["txSummary"],
            "åˆ›å»ºæ—¶é—´": ["createdAt"]
        }

        fields = []
        for keyword, field_list in field_mapping.items():
            if keyword in logic:
                fields.extend(field_list)

        return list(set(fields))

    def _load_available_knowledge(self) -> List[Dict[str, Any]]:
        """
        ä»è§„åˆ™å¼•æ“è·å–å¯ç”¨çš„çŸ¥è¯†å…ƒæ•°æ®

        Returns:
            çŸ¥è¯†å…ƒæ•°æ®åˆ—è¡¨ï¼ŒåŒ…å«idå’Œdescription
        """
        try:
            url = "http://localhost:8081/api/rules/getKnowledgeMeta"
            headers = {
                "Accept": "*/*",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Content-Type": "application/json",
                "User-Agent": "PostmanRuntime-ApipostRuntime/1.1.0"
            }

            response = requests.post(url, headers=headers, json={}, timeout=30)

            if response.status_code == 200:
                knowledge_meta = response.json()
                if isinstance(knowledge_meta, list):
                    print(f"âœ… æˆåŠŸè·å– {len(knowledge_meta)} ä¸ªçŸ¥è¯†å…ƒæ•°æ®")
                    return knowledge_meta
                else:
                    print(f"âš ï¸ çŸ¥è¯†å…ƒæ•°æ®æ ¼å¼å¼‚å¸¸: {knowledge_meta}")
                    return []
            else:
                print(f"âŒ è·å–çŸ¥è¯†å…ƒæ•°æ®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”å†…å®¹: {response.text}")
                return []

        except Exception as e:
            print(f"âŒ è·å–çŸ¥è¯†å…ƒæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []

    def _load_available_metrics(self) -> List[Dict[str, str]]:
        """
        ä»çŸ¥è¯†åº“ä¸­æå–å¯ç”¨çš„æŒ‡æ ‡åˆ—è¡¨

        Returns:
            æŒ‡æ ‡åˆ—è¡¨ï¼ŒåŒ…å«nameå’Œdescriptionå­—æ®µ
        """
        knowledge_list = self._load_available_knowledge()

        metrics = []
        for knowledge in knowledge_list:
            knowledge_id = knowledge.get("id", "")
            description = knowledge.get("description", "")

            # ä»çŸ¥è¯†IDä¸­æå–æŒ‡æ ‡åç§°
            if knowledge_id.startswith("metric-"):
                metric_name = knowledge_id.replace("metric-", "")

                # ä»æè¿°ä¸­æå–æ›´ç®€æ´çš„æŒ‡æ ‡æè¿°
                short_description = self._extract_metric_description(description)

                metrics.append({
                    "name": metric_name,
                    "description": short_description,
                    "type": self._classify_metric_type(metric_name, description)
                })

        print(f"âœ… ä»çŸ¥è¯†åº“ä¸­æå–äº† {len(metrics)} ä¸ªå¯ç”¨æŒ‡æ ‡")
        return metrics

    def _extract_metric_description(self, full_description: str) -> str:
        """ä»å®Œæ•´æè¿°ä¸­æå–ç®€æ´çš„æŒ‡æ ‡æè¿°"""
        # ç§»é™¤"å› å­æ¦‚è¿°ï¼š"ç­‰å‰ç¼€
        description = full_description.replace("å› å­æ¦‚è¿°ï¼š", "").strip()

        # å¦‚æœæè¿°å¤ªé•¿ï¼Œå–å‰50ä¸ªå­—ç¬¦
        if len(description) > 50:
            description = description[:50] + "..."

        return description

    def _classify_metric_type(self, metric_name: str, description: str) -> str:
        """æ ¹æ®æŒ‡æ ‡åç§°å’Œæè¿°åˆ†ç±»æŒ‡æ ‡ç±»å‹"""
        if any(keyword in metric_name for keyword in ["æ”¶å…¥", "æ”¯å‡º", "é‡‘é¢", "äº¤æ˜“ç¬”æ•°"]):
            return "åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡"
        elif any(keyword in metric_name for keyword in ["æ—¶é—´èŒƒå›´", "æ—¶é—´è·¨åº¦"]):
            return "æ—¶é—´åˆ†ææŒ‡æ ‡"
        elif any(keyword in metric_name for keyword in ["æ¯”ä¾‹", "å æ¯”", "æ„æˆ"]):
            return "ç»“æ„åˆ†ææŒ‡æ ‡"
        elif any(keyword in metric_name for keyword in ["æ’å", "TOP", "å‰ä¸‰"]):
            return "ä¸“é¡¹åˆ†ææŒ‡æ ‡"
        elif any(keyword in metric_name for keyword in ["è´¦æˆ·", "æ•°é‡"]):
            return "è´¦æˆ·åˆ†ææŒ‡æ ‡"
        else:
            return "å…¶ä»–æŒ‡æ ‡"

    def _match_metric_to_knowledge(self, metric_name: str, metric_description: str) -> str:
        """
        æ ¹æ®æŒ‡æ ‡åç§°å’Œæè¿°åŒ¹é…æœ€åˆé€‚çš„çŸ¥è¯†ID

        Args:
            metric_name: æŒ‡æ ‡åç§°
            metric_description: æŒ‡æ ‡æè¿°

        Returns:
            åŒ¹é…çš„çŸ¥è¯†IDï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if not self.available_knowledge:
            return ""

        # ç²¾ç¡®åŒ¹é…ï¼šç›´æ¥ç”¨æŒ‡æ ‡åç§°åŒ¹é…çŸ¥è¯†ID
        for knowledge in self.available_knowledge:
            knowledge_id = knowledge.get("id", "")
            # å»æ‰å‰ç¼€åŒ¹é…ï¼Œå¦‚ "metric-åˆ†æè´¦æˆ·æ•°é‡" åŒ¹é… "åˆ†æè´¦æˆ·æ•°é‡"
            if knowledge_id.startswith("metric-") and knowledge_id.replace("metric-", "") == metric_name:
                print(f"ğŸ”— ç²¾ç¡®åŒ¹é…æŒ‡æ ‡ '{metric_name}' -> çŸ¥è¯†ID: {knowledge_id}")
                return knowledge_id

        # æ‰©å±•åŒ¹é…ï¼šåŒ¹é…æ›´å¤šçš„å†œä¸šç›¸å…³æŒ‡æ ‡
        if "å†œä¸š" in metric_name:
            if "æ€»ç»è¥æ”¶å…¥" in metric_name:
                # åŒ¹é…å†œä¸šæ€»ç»è¥æ”¶å…¥
                for knowledge in self.available_knowledge:
                    if knowledge.get("id") == "metric-å†œä¸šæ€»ç»è¥æ”¶å…¥":
                        print(f"ğŸ”— æ‰©å±•åŒ¹é…æŒ‡æ ‡ '{metric_name}' -> çŸ¥è¯†ID: metric-å†œä¸šæ€»ç»è¥æ”¶å…¥")
                        return "metric-å†œä¸šæ€»ç»è¥æ”¶å…¥"
            if "æ€»ç»è¥æ”¯å‡º" in metric_name:
                # åŒ¹é…å†œä¸šæ€»ç»è¥æ”¯å‡º
                for knowledge in self.available_knowledge:
                    if knowledge.get("id") == "metric-å†œä¸šæ€»ç»è¥æ”¯å‡º":
                        print(f"ğŸ”— æ‰©å±•åŒ¹é…æŒ‡æ ‡ '{metric_name}' -> çŸ¥è¯†ID: metric-å†œä¸šæ€»ç»è¥æ”¯å‡º")
                        return "metric-å†œä¸šæ€»ç»è¥æ”¯å‡º"
            if "äº¤æ˜“å¯¹æ‰‹æ”¶å…¥æ’åTOP3" in metric_name or "æ”¶å…¥æ’å" in metric_name:
                # åŒ¹é…å†œä¸šäº¤æ˜“å¯¹æ‰‹æ”¶å…¥TOP3
                for knowledge in self.available_knowledge:
                    if knowledge.get("id") == "metric-å†œä¸šäº¤æ˜“å¯¹æ‰‹ç»è¥æ”¶å…¥top3":
                        print(f"ğŸ”— æ‰©å±•åŒ¹é…æŒ‡æ ‡ '{metric_name}' -> çŸ¥è¯†ID: metric-å†œä¸šäº¤æ˜“å¯¹æ‰‹ç»è¥æ”¶å…¥top3")
                        return "metric-å†œä¸šäº¤æ˜“å¯¹æ‰‹ç»è¥æ”¶å…¥top3"
            if "äº¤æ˜“å¯¹æ‰‹æ”¯å‡ºæ’åTOP3" in metric_name or "æ”¯å‡ºæ’å" in metric_name:
                # åŒ¹é…å†œä¸šäº¤æ˜“å¯¹æ‰‹æ”¯å‡ºTOP3
                for knowledge in self.available_knowledge:
                    if knowledge.get("id") == "metric-å†œä¸šäº¤æ˜“å¯¹æ‰‹ç»è¥æ”¯å‡ºtop3":
                        print(f"ğŸ”— æ‰©å±•åŒ¹é…æŒ‡æ ‡ '{metric_name}' -> çŸ¥è¯†ID: metric-å†œä¸šäº¤æ˜“å¯¹æ‰‹ç»è¥æ”¯å‡ºtop3")
                        return "metric-å†œä¸šäº¤æ˜“å¯¹æ‰‹ç»è¥æ”¯å‡ºtop3"

        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…
        keywords = [metric_name]
        if metric_description:
            # ä»æè¿°ä¸­æå–å…³é”®ä¿¡æ¯
            desc_lower = metric_description.lower()
            if "æ”¶å…¥" in metric_name or "æ”¶å…¥" in desc_lower:
                keywords.extend(["æ”¶å…¥", "æ€»æ”¶å…¥", "ç»è¥æ”¶å…¥"])
            if "æ”¯å‡º" in metric_name or "æ”¯å‡º" in desc_lower:
                keywords.extend(["æ”¯å‡º", "æ€»æ”¯å‡º", "ç»è¥æ”¯å‡º"])
            if "æ’å" in metric_name or "top" in desc_lower:
                keywords.append("æ’å")
            if "æ¯”ä¾‹" in metric_name or "å æ¯”" in desc_lower:
                keywords.append("æ¯”ä¾‹")
            if "æ—¶é—´èŒƒå›´" in metric_name:
                keywords.append("æ—¶é—´èŒƒå›´")
            if "è´¦æˆ·" in metric_name:
                keywords.append("è´¦æˆ·")

        best_match = None
        best_score = 0

        for knowledge in self.available_knowledge:
            knowledge_id = knowledge.get("id", "")
            knowledge_desc = knowledge.get("description", "").lower()

            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            for keyword in keywords:
                if keyword.lower() in knowledge_desc:
                    score += 1

            # è¡Œä¸šåŒ¹é…åŠ åˆ†
            if "é»‘è‰²é‡‘å±" in knowledge_desc and "é»‘è‰²é‡‘å±" in metric_name:
                score += 2
            if "å†œä¸š" in knowledge_desc and "å†œä¸š" in metric_name:
                score += 2

            # ç›´æ¥åç§°åŒ¹é…åŠ åˆ†
            if metric_name.lower() in knowledge_desc:
                score += 3

            if score > best_score:
                best_score = score
                best_match = knowledge_id

        if best_match and best_score > 0:
            print(f"ğŸ”— å…³é”®è¯åŒ¹é…æŒ‡æ ‡ '{metric_name}' -> çŸ¥è¯†ID: {best_match} (åŒ¹é…åˆ†æ•°: {best_score})")
            return best_match

        print(f"âŒ æŒ‡æ ‡ '{metric_name}' æœªæ‰¾åˆ°åŒ¹é…çš„çŸ¥è¯†ID")
        return ""


async def generate_report_outline(question: str, industry: str, sample_data: List[Dict[str, Any]], api_key: str, max_retries: int = 3, retry_delay: float = 2.0) -> ReportOutline:
    """
    ç”ŸæˆæŠ¥å‘Šå¤§çº²çš„ä¸»å‡½æ•°ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶

    Args:
        question: ç”¨æˆ·æŸ¥è¯¢é—®é¢˜
        industry: è¡Œä¸š
        sample_data: æ•°æ®æ ·æœ¬
        api_key: APIå¯†é’¥
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡
        retry_delay: é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤2ç§’

    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šå¤§çº²
    """
    import asyncio
    import time

    agent = OutlineGeneratorAgent(api_key)

    print(f"ğŸ“ å¼€å§‹ç”ŸæˆæŠ¥å‘Šå¤§çº²ï¼ˆæœ€å¤šé‡è¯• {max_retries} æ¬¡ï¼‰...")

    for attempt in range(max_retries):
        try:
            print(f"   å°è¯• {attempt + 1}/{max_retries}...")
            start_time = time.time()

            outline = await agent.generate_outline(question, industry, sample_data)

            elapsed_time = time.time() - start_time
            print(".2f")
            print("\nğŸ“ å¤§çº²ç”ŸæˆæˆåŠŸï¼š")
            print(f"   æ ‡é¢˜ï¼š{outline.report_title}")
            print(f"   ç« èŠ‚æ•°ï¼š{len(outline.sections)}")
            print(f"   æŒ‡æ ‡æ•°ï¼š{len(outline.global_metrics)}")

            return outline

        except Exception as e:
            elapsed_time = time.time() - start_time if 'start_time' in locals() else 0
            print(".2f")
            print(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")

            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
            if attempt < max_retries - 1:
                print(f"   â³ {retry_delay} ç§’åè¿›è¡Œç¬¬ {attempt + 2} æ¬¡é‡è¯•...")
                await asyncio.sleep(retry_delay)
                # å¢åŠ é‡è¯•é—´éš”ï¼Œé¿å…é¢‘ç¹è°ƒç”¨
                retry_delay = min(retry_delay * 1.5, 10.0)  # æœ€å¤šç­‰å¾…10ç§’
            else:
                print(f"   âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")

    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åï¼Œä½¿ç”¨é»˜è®¤ç»“æ„
    print("âš ï¸ æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤§çº²ç»“æ„")

    # è·å–å®é™…å¯ç”¨çš„æŒ‡æ ‡æ¥æ„å»ºé»˜è®¤å¤§çº²
    available_metrics = self._load_available_metrics()

    # é€‰æ‹©ä¸€äº›åŸºç¡€æŒ‡æ ‡ä½œä¸ºé»˜è®¤å€¼
    default_metric_ids = []
    default_global_metrics = []

    # ä¼˜å…ˆé€‰æ‹©åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
    base_metrics = [m for m in available_metrics if m.get('type') == 'åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡']
    if base_metrics:
        # é€‰æ‹©å‰3ä¸ªåŸºç¡€æŒ‡æ ‡
        for metric in base_metrics[:3]:
            metric_name = metric['name']
            knowledge_id = f"metric-{metric_name}"
            default_metric_ids.append(knowledge_id)
            default_global_metrics.append(MetricRequirement(
                metric_id=knowledge_id,
                metric_name=metric_name,
                calculation_logic=f"ä½¿ç”¨è§„åˆ™å¼•æ“è®¡ç®—{metric_name}: {metric.get('description', '')}",
                required_fields=["transactions"],
                dependencies=[]
            ))

    # å¦‚æœåŸºç¡€æŒ‡æ ‡ä¸å¤Ÿï¼Œè¡¥å……å…¶ä»–ç±»å‹çš„æŒ‡æ ‡
    if len(default_metric_ids) < 3:
        other_metrics = [m for m in available_metrics if m.get('type') != 'åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡']
        for metric in other_metrics[:3-len(default_metric_ids)]:
            metric_name = metric['name']
            knowledge_id = f"metric-{metric_name}"
            default_metric_ids.append(knowledge_id)
            default_global_metrics.append(MetricRequirement(
                metric_id=knowledge_id,
                metric_name=metric_name,
                calculation_logic=f"ä½¿ç”¨è§„åˆ™å¼•æ“è®¡ç®—{metric_name}: {metric.get('description', '')}",
                required_fields=["transactions"],
                dependencies=[]
            ))

    # åˆ›å»ºä½¿ç”¨å®é™…æŒ‡æ ‡çš„é»˜è®¤å¤§çº²
    default_outline = ReportOutline(
        report_title="é»˜è®¤äº¤æ˜“åˆ†ææŠ¥å‘Š",
        sections=[
            ReportSection(
                section_id="sec_1",
                title="äº¤æ˜“æ¦‚è§ˆ",
                description="åŸºç¡€äº¤æ˜“æƒ…å†µåˆ†æ",
                metrics_needed=default_metric_ids
            )
        ],
        global_metrics=default_global_metrics
    )
    return default_outline
