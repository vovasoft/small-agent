#!/usr/bin/env python3
"""
æ‰¹é‡ä¿å­˜è§„åˆ™åˆ°è§„åˆ™å¼•æ“
===================

å°†ç”Ÿæˆçš„JSONè§„åˆ™æ–‡ä»¶æ‰¹é‡ä¿å­˜åˆ°è§„åˆ™å¼•æ“API
"""

import json
import os
import requests
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed


def save_single_rule(json_file_path, api_url="http://localhost:8081"):
    """
    ä¿å­˜å•ä¸ªè§„åˆ™åˆ°è§„åˆ™å¼•æ“

    Args:
        json_file_path: JSONæ–‡ä»¶è·¯å¾„
        api_url: APIåŸºç¡€URL

    Returns:
        ä¿å­˜ç»“æœå­—å…¸
    """
    try:
        # è¯»å–JSONæ–‡ä»¶
        with open(json_file_path, 'r', encoding='utf-8') as f:
            payload = json.load(f)

        rule_name = payload['decisionKnowledge']['name']
        rule_id = payload['decisionKnowledge']['id']

        # æ„å»ºAPI URL
        url = f"{api_url}/api/rules/saveDecisionKnowledge"

        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'Accept': '*/*',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Content-Type': 'application/json',
            'User-Agent': 'PostmanRuntime-ApipostRuntime/1.1.0'
        }

        # å‘é€è¯·æ±‚
        print(f"ğŸ“¤ æ­£åœ¨ä¿å­˜è§„åˆ™: {rule_name} (ID: {rule_id})")
        response = requests.post(url, headers=headers, json=payload, timeout=30)

        if response.status_code == 200:
            print(f"âœ… è§„åˆ™ä¿å­˜æˆåŠŸ: {rule_name}")
            return {
                'success': True,
                'rule_name': rule_name,
                'rule_id': rule_id,
                'file_path': json_file_path,
                'response': response.text
            }
        else:
            print(f"âŒ è§„åˆ™ä¿å­˜å¤±è´¥ [{response.status_code}]: {rule_name}")
            return {
                'success': False,
                'rule_name': rule_name,
                'rule_id': rule_id,
                'file_path': json_file_path,
                'error': f"HTTP {response.status_code}: {response.text}"
            }

    except Exception as e:
        rule_name = Path(json_file_path).stem.replace('rule_', '')
        print(f"âŒ å¤„ç†å¼‚å¸¸: {rule_name} - {e}")
        return {
            'success': False,
            'rule_name': rule_name,
            'file_path': json_file_path,
            'error': str(e)
        }


def save_rules_batch(rules_dir, api_url="http://localhost:8081", max_workers=2):
    """
    æ‰¹é‡ä¿å­˜è§„åˆ™åˆ°è§„åˆ™å¼•æ“

    Args:
        rules_dir: åŒ…å«è§„åˆ™JSONæ–‡ä»¶çš„ç›®å½•
        api_url: APIåŸºç¡€URL
        max_workers: æœ€å¤§å¹¶å‘æ•°
    """
    print("ğŸš€ æ‰¹é‡ä¿å­˜è§„åˆ™åˆ°è§„åˆ™å¼•æ“")
    print("=" * 50)
    print(f"ğŸ“ è§„åˆ™ç›®å½•: {rules_dir}")
    print(f"ğŸŒ APIåœ°å€: {api_url}")
    print(f"âš¡ å¹¶å‘æ•°: {max_workers}")

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(rules_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {rules_dir}")
        return

    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    json_files = list(Path(rules_dir).glob("*.json"))
    if not json_files:
        print(f"âŒ æœªæ‰¾åˆ°JSONæ–‡ä»¶åœ¨ç›®å½•: {rules_dir}")
        return

    total_files = len(json_files)
    print(f"ğŸ“Š å‘ç° {total_files} ä¸ªè§„åˆ™æ–‡ä»¶")
    print()

    # å¼€å§‹æ‰¹é‡ä¿å­˜
    success_count = 0
    failed_rules = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_file = {
            executor.submit(save_single_rule, str(json_file), api_url): json_file
            for json_file in json_files
        }

        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_file):
            json_file = future_to_file[future]
            try:
                result = future.result()
                if result['success']:
                    success_count += 1
                else:
                    failed_rules.append(result)
            except Exception as e:
                failed_rules.append({
                    'rule_name': Path(json_file).stem.replace('rule_', ''),
                    'file_path': str(json_file),
                    'error': str(e)
                })

    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š ä¿å­˜ç»“æœç»Ÿè®¡")
    print(f"âœ… æˆåŠŸä¿å­˜: {success_count}/{total_files}")
    print(f"âŒ ä¿å­˜å¤±è´¥: {len(failed_rules)}/{total_files}")

    if failed_rules:
        print("\nâŒ å¤±è´¥çš„è§„åˆ™:")
        for failed in failed_rules:
            print(f"   - {failed['rule_name']}: {failed.get('error', 'æœªçŸ¥é”™è¯¯')}")

    return success_count, failed_rules


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='æ‰¹é‡ä¿å­˜è§„åˆ™åˆ°è§„åˆ™å¼•æ“')
    parser.add_argument('--rules-dir', '-d', default='generated_metrics_rules',
                       help='åŒ…å«è§„åˆ™JSONæ–‡ä»¶çš„ç›®å½•')
    parser.add_argument('--api-url', '-u', default='http://localhost:8081',
                       help='è§„åˆ™å¼•æ“APIåŸºç¡€URL')
    parser.add_argument('--workers', '-w', type=int, default=2,
                       help='å¹¶å‘ä¿å­˜æ•°ï¼ˆé»˜è®¤2ï¼Œé¿å…APIè¿‡è½½ï¼‰')

    args = parser.parse_args()

    success_count, failed_rules = save_rules_batch(
        rules_dir=args.rules_dir,
        api_url=args.api_url,
        max_workers=args.workers
    )

    if success_count > 0:
        print(f"\nğŸ‰ æ‰¹é‡ä¿å­˜å®Œæˆï¼æˆåŠŸä¿å­˜ {success_count} ä¸ªè§„åˆ™")
    else:
        print("\nâŒ æ‰¹é‡ä¿å­˜å¤±è´¥ï¼")
        exit(1)


if __name__ == "__main__":
    main()
